#!/usr/bin/env python3
"""
Test workflow with a title that should work better
"""

import asyncio
import json
import sys
sys.path.append('/home/claude-workflow')

from mcp_servers.airtable_server import AirtableMCPServer
from mcp_servers.product_category_extractor_server import ProductCategoryExtractorMCPServer
from mcp_servers.amazon_category_scraper import AmazonCategoryScraper

async def test_workflow_with_different_title():
    """Test workflow with a title that should work better"""
    
    # Load config
    with open('/home/claude-workflow/config/api_keys.json', 'r') as f:
        config = json.load(f)
    
    # Initialize servers
    airtable = AirtableMCPServer(
        config['airtable_api_key'],
        config['airtable_base_id'],
        config['airtable_table_name']
    )
    extractor = ProductCategoryExtractorMCPServer(config['anthropic_api_key'])
    scraper = AmazonCategoryScraper(config)
    
    # Test with different titles
    test_titles = [
        "ğŸ”¥ TOP 5 Gaming Headsets That Will Blow Your Mind! ğŸ®",
        "BEST Bluetooth Speakers You Need! ğŸ”Š (Bass Test)",
        "TOP 5 Phone Cases That Actually Work! ğŸ“±",
        "ğŸ”¥ 5 INSANE Wireless Chargers You Need! âš¡ï¸",
        "INSANE Monitors You NEED in 2025! ğŸ”¥"
    ]
    
    for title in test_titles:
        print(f"\nğŸ§ª Testing title: {title}")
        
        # Step 1: Extract category
        print("ğŸ” Extracting category...")
        category_result = await extractor.extract_product_category(title)
        
        if not category_result['success']:
            print(f"âŒ Category extraction failed: {category_result.get('error')}")
            continue
        
        clean_category = category_result['primary_category']
        print(f"âœ… Extracted: {clean_category}")
        
        # Step 2: Try Amazon scraping
        print("ğŸ›’ Testing Amazon scraping...")
        search_terms = [clean_category] + category_result['search_terms']
        
        for term in search_terms[:3]:
            print(f"   ğŸ” Trying: {term}")
            result = await scraper.get_top_5_products(term)
            
            if result['success']:
                print(f"   âœ… Success! Found {len(result['products'])} products")
                print(f"   ğŸ¯ Working title: {title}")
                print(f"   ğŸ¯ Working search term: {term}")
                return True
            else:
                print(f"   âŒ Failed: {result.get('error', 'Unknown error')}")
    
    print("\nâŒ No working titles found")
    return False

if __name__ == "__main__":
    result = asyncio.run(test_workflow_with_different_title())
    if result:
        print("\nğŸ‰ Found a working combination!")
    else:
        print("\nğŸ’¥ No working combinations found")