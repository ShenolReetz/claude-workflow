#!/usr/bin/env python3
"""
Amazon Category Scraper - Searches products by category and ranks by Reviews Ã— Rating
"""
import asyncio
import json
import logging
import re
import time
from typing import Dict, List, Optional
from urllib.parse import quote
import httpx
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class AmazonCategoryScraper:
    """Scrapes Amazon products by category and ranks them by review score"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.api_key = config.get('scrapingdog_api_key', '')
        self.affiliate_tag = config.get('amazon_associate_id', 'reviewch3kr0d-20')
        self.base_url = 'https://api.scrapingdog.com/scrape'
        self.last_request_time = 0
        self.min_delay = 6  # ScrapingDog requires 6 second delays
        
        if not self.api_key:
            logger.warning("ScrapingDog API key not found in config!")
    
    def extract_category_from_title(self, title: str) -> str:
        """Extract category keywords from Airtable title"""
        # Remove common prefixes
        title_lower = title.lower()
        prefixes = [
            'top 5 products based on amazon', 
            'top 5 products based on', 
            'top 5', 'best 5', 'top', 'best',
            'editor\'s picks', 'picks'
        ]
        
        for prefix in prefixes:
            if title_lower.startswith(prefix):
                title_lower = title_lower[len(prefix):].strip()
        
        # Remove common suffixes
        suffixes = ['category', 'editor\'s picks', 'picks', '2025', '2024']
        for suffix in suffixes:
            if title_lower.endswith(suffix):
                title_lower = title_lower[:-len(suffix)].strip()
        
        # Clean up common words that don't help search
        cleanup_words = ['&', 'accessories']
        for word in cleanup_words:
            if word in title_lower:
                title_lower = title_lower.replace(word, ' ').strip()
        
        # Clean up multiple spaces
        title_lower = ' '.join(title_lower.split())
        
        return title_lower.strip()
    
    async def rate_limit(self):
        """Implement rate limiting for ScrapingDog"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_delay:
            delay = self.min_delay - time_since_last
            logger.info(f"Rate limiting: waiting {delay:.2f} seconds")
            await asyncio.sleep(delay)
        
        self.last_request_time = time.time()
    
    async def search_category_products(self, category_title: str, max_products: int = 20) -> List[Dict]:
        """Search Amazon for products in a category and return top products by review score"""
        try:
            await self.rate_limit()
            
            # Extract category from title
            category = self.extract_category_from_title(category_title)
            logger.info(f"ðŸ” Searching Amazon category: {category}")
            
            # Amazon search URL
            target_url = f"https://www.amazon.com/s?k={quote(category)}&s=review-rank"
            
            # ScrapingDog parameters
            params = {
                'api_key': self.api_key,
                'url': target_url,
                'dynamic': 'false',
                'country': 'us'
            }
            
            async with httpx.AsyncClient(timeout=60.0) as client:
                response = await client.get(self.base_url, params=params)
                
                if response.status_code == 429:
                    logger.error("ScrapingDog rate limit hit. Waiting 10 seconds...")
                    await asyncio.sleep(10)
                    return []
                
                if response.status_code != 200:
                    logger.error(f"ScrapingDog API error: {response.status_code}")
                    return []
                
                # Parse the HTML response
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # Find all products
                products = soup.select('[data-component-type="s-search-result"]')
                
                if not products:
                    logger.warning(f"No products found for category: {category}")
                    return []
                
                logger.info(f"Found {len(products)} products in search results")
                
                # Extract product details
                product_list = []
                for product in products[:max_products]:
                    try:
                        asin = product.get('data-asin', '')
                        if not asin:
                            continue
                        
                        # Title - try multiple selectors for robustness
                        title = ''
                        title_selectors = ['h2 span', '.a-link-normal span', 'h2 a span', 'h2']
                        for selector in title_selectors:
                            title_elem = product.select_one(selector)
                            if title_elem:
                                title = title_elem.text.strip()
                                if title:  # Only use if we got actual text
                                    break
                        
                        # Price
                        price_elem = product.select_one('.a-price-whole')
                        price = price_elem.text.strip() if price_elem else 'N/A'
                        
                        # Rating
                        rating_elem = product.select_one('span.a-icon-alt')
                        rating_text = rating_elem.text if rating_elem else '0 out of 5 stars'
                        rating = float(rating_text.split()[0]) if rating_text else 0.0
                        
                        # Review count
                        review_elem = product.select_one('span.a-size-base.s-underline-text')
                        review_text = review_elem.text.strip() if review_elem else '0'
                        # Extract number from text like "1,234" or "1234"
                        review_count = int(review_text.replace(',', '')) if review_text.replace(',', '').isdigit() else 0
                        
                        # Image
                        img_elem = product.select_one('img.s-image')
                        image_url = img_elem.get('src', '') if img_elem else ''
                        
                        # Calculate review score (reviews Ã— rating)
                        review_score = review_count * rating
                        
                        product_data = {
                            'asin': asin,
                            'title': title,
                            'price': price,
                            'rating': rating,
                            'review_count': review_count,
                            'review_score': review_score,
                            'image_url': image_url,
                            'affiliate_link': f"https://www.amazon.com/dp/{asin}?tag={self.affiliate_tag}"
                        }
                        
                        product_list.append(product_data)
                        
                    except Exception as e:
                        logger.warning(f"Error parsing product: {e}")
                        continue
                
                # Sort by review score (reviews Ã— rating)
                product_list.sort(key=lambda x: x['review_score'], reverse=True)
                
                logger.info(f"âœ… Successfully scraped {len(product_list)} products")
                return product_list[:5]  # Return top 5 products
                
        except Exception as e:
            logger.error(f"Error searching category {category_title}: {str(e)}")
            return []
    
    async def get_top_5_products(self, category_title: str) -> Dict:
        """Get top 5 products for a category based on review score"""
        try:
            # Search for products
            products = await self.search_category_products(category_title)
            
            if not products:
                return {
                    'success': False,
                    'error': 'No products found',
                    'products': []
                }
            
            # Format results for Airtable
            airtable_data = {}
            product_results = {}
            
            for i, product in enumerate(products[:5], 1):
                # Add to Airtable fields
                airtable_data[f'ProductNo{i}Title'] = product['title']
                airtable_data[f'ProductNo{i}AffiliateLink'] = product['affiliate_link']
                airtable_data[f'ProductNo{i}Photo'] = product['image_url']
                # Convert price to number format for Airtable
                price_str = product['price']
                if isinstance(price_str, str):
                    # Remove $ symbol and convert to float
                    price_clean = price_str.replace('$', '').replace(',', '')
                    try:
                        price_num = float(price_clean)
                        airtable_data[f'ProductNo{i}Price'] = price_num
                    except ValueError:
                        # If conversion fails, store as 0
                        airtable_data[f'ProductNo{i}Price'] = 0.0
                        logger.warning(f"Could not convert price '{price_str}' to number, using 0.0")
                else:
                    airtable_data[f'ProductNo{i}Price'] = product['price']
                airtable_data[f'ProductNo{i}Rating'] = str(product['rating'])
                airtable_data[f'ProductNo{i}Reviews'] = str(product['review_count'])
                airtable_data[f'ProductNo{i}Score'] = str(product['review_score'])
                
                # Add to product results for other uses
                product_results[f'product_{i}'] = product
            
            logger.info(f"âœ… Selected top 5 products based on review score")
            for i, product in enumerate(products[:5], 1):
                logger.info(f"  {i}. {product['title'][:50]}... (Score: {product['review_score']:.0f})")
            
            return {
                'success': True,
                'products': products[:5],
                'airtable_data': airtable_data,
                'product_results': product_results,
                'total_found': len(products)
            }
            
        except Exception as e:
            logger.error(f"Error getting top 5 products: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'products': []
            }